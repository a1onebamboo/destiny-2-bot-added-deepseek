# destiny-2-bot-added-deepseek
import requests
import json

messages = [{"role": "system",
"content":
'''
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‘½è¿ï¼šç¾¤æ˜Ÿæ¸¸æˆä¸“å®¶ï¼Œç²¾é€šæ¸¸æˆçš„æ‰€æœ‰æ–¹é¢ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå›ç­”è¦ï¼š
        1. å‡†ç¡®ã€è¯¦ç»†ä½†ç®€æ´
        2. åŒ…å«å®ç”¨çš„æ”»ç•¥å’ŒæŠ€å·§
        3. å¦‚æœæ˜¯æ­¦å™¨ï¼Œè¦è¯´æ˜è·å–æ–¹å¼å’Œæ¨èperk
        4. å¦‚æœæ˜¯å‰¯æœ¬ï¼Œè¦è¯´æ˜æœºåˆ¶å’Œæ‰“æ³•
        5. ä¸æŸ¥è¯¢æ¸¸æˆç©å®¶ä¸ªäººä¿¡æ¯å†…å®¹
        6. ä¿¡æ¯å…·æœ‰æ—¶æ•ˆæ€§,å½“å‰èµ›å­£ä¸ºå®¿å‘½è¾¹ç¼˜
'''}
]

url = "https://api.deepseek.com/chat/completions"
headers = {
  'Content-Type': 'application/json',
  'Accept': 'application/json',
  'Authorization': 'Bearer sk-7396d4f233e54902966769c5b4ebacaf'
}

def content():
  response = requests.request("POST", url, headers=headers, data=data)
  response = json.loads(response.text)#å°†response.textï¼ˆä¸ºjsonï¼‰å†…å®¹è§£ç ä¸ºpythonç±»å‹
  message = response['choices']#choicesæ˜¯åˆ—è¡¨
  message = message[0]#è½¬åŒ–ä¸ºå­—å…¸
  message = message['message']#æå–å…¶ä¸­messageå†…å®¹ï¼Œ,ä¹Ÿæ˜¯ç³»ç»Ÿå›å¤å†…å®¹,å­—å…¸ç±»å‹,å†…å®¹{'role': 'assistant', 'content':'','reasoning_content':}
  content = message['content']#ç³»ç»Ÿå›å¤å†…å®¹
  reasoning_content = message['reasoning_content']#ç³»ç»Ÿæ€è€ƒå†…å®¹
  del message['reasoning_content']
  messages.append(message)#å°†ç³»ç»Ÿå›å¤å†…å®¹æ·»åŠ åˆ°messagesæœ«å°¾ï¼Œè¿›è¡Œå¯¹è®ºå¯¹å¯¹è¯å‡†å¤‡
  # print('å“åº”å†…å®¹ï¼ˆpyï¼‰', response)
  # print('messageå†…å®¹', message)
  # print('ä¼ å…¥messagesåºåˆ—ï¼š', messages)
  print('æ€è€ƒå†…å®¹ï¼š', reasoning_content)  # æ€è€ƒå†…å®¹
  print('å¯¹è¯å†…å®¹ï¼š', content)  # å¯¹è¯å†…å®¹
#æ³¨ï¼šå¤šè½®å¯¹è¯ä¸èƒ½æŠŠreasoning_contentä¼ å…¥messages åºåˆ—

while True:

  user_input = input('ç”¨æˆ·:')
  messages.append({"content": user_input, "role": "user"})#æé—®å†…å®¹

  data = json.dumps({
    "messages": messages,
    "model": "deepseek-reasoner",
    "frequency_penalty": 1,
    "max_tokens": 32768,
    "presence_penalty": 0,
    "response_format": {
      "type": "text"
    },
    "stop": None,
    "stream": False,
    "stream_options": None,
    "temperature": 1,
    "top_p": 1,
    "tools": None,
    "tool_choice": "none",
    "logprobs": False,
    "top_logprobs": None
  })

  content()

  if user_input == 'é€€å‡º':
    break




'''
response.textå†…å®¹
{'id': 'ec9c2191-b412-4405-a2d3-184a16699a3f',
 'object': 'chat.completion', åˆ›å»ºèŠå¤©å®Œæˆæ—¶çš„ Unix æ—¶é—´æˆ³ï¼ˆä»¥ç§’ä¸ºå•ä½ï¼‰ã€‚
 'created': 1760272141,
  'model': 'deepseek-chat', 
  
'choices': [{'index': 0, 
'message': {'role': 'assistant', 'content': "Hello! ğŸ‘‹ How can I help you today? Feel free to ask me anythingâ€”I'm here to assist! ğŸ˜Š"}, 
'logprobs': None, 'finish_reason': 'stop'}], 

'usage': {'prompt_tokens': 10, ç”¨æˆ· prompt æ‰€åŒ…å«çš„ token æ•°ã€‚è¯¥å€¼ç­‰äº prompt_cache_hit_tokens + prompt_cache_miss_tokens
'completion_tokens': 26, æ¨¡å‹ completion äº§ç”Ÿçš„ token æ•°ã€‚
'total_tokens': 36, è¯¥è¯·æ±‚ä¸­ï¼Œæ‰€æœ‰ token çš„æ•°é‡ï¼ˆprompt + completionï¼‰ã€‚
'prompt_tokens_details': {'cached_tokens': 0}, 
'prompt_cache_hit_tokens': 0,'prompt_cache_miss_tokens': 10},ç”¨æˆ· prompt ä¸­ï¼Œå‘½ä¸­ä¸Šä¸‹æ–‡ç¼“å­˜çš„ token æ•°ã€‚
'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache'}è¯¥æŒ‡çº¹ä»£è¡¨æ¨¡å‹è¿è¡Œæ—¶é‡‡ç”¨çš„åç«¯é…ç½®ã€‚
prompt_cache_miss_tokensï¼šç”¨æˆ· prompt ä¸­ï¼Œæœªå‘½ä¸­ä¸Šä¸‹æ–‡ç¼“å­˜çš„ token æ•°ã€‚

completion tokens çš„è¯¦ç»†ä¿¡æ¯ï¼š
reasoning_tokensï¼š
æ¨ç†æ¨¡å‹æ‰€äº§ç”Ÿçš„æ€ç»´é“¾ token æ•°é‡
'''

# print(respondse)#respondse.text(è¿”å›å“åº”çš„å†…å®¹ï¼Œunicode ç±»å‹æ•°æ®),è§£ç ä¸ºpyç±»å‹
